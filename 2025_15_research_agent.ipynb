{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw_Ao9uHkECm"
      },
      "source": [
        "# **LangGraph Research Assistant Mockup**\n",
        "\n",
        "Este ejercicio ejemplifica la arquitectura de un agente en LangGraph, sin integrar LLMs ni herramientas externas. No pretende construir un agente operativo, sino descomponer la orquestación de flujos complejos mediante grafos. A partir de un mockup funcional, se abordan el estado compartido, los nodos, el enrutamiento condicional y el ensamblaje del grafo. Este enfoque permite comprender la estructura y la mecánica de paso de mensajes que habilitan agentes autónomos, separando la lógica de orquestación de la complejidad de las APIs reales.\n",
        "\n",
        "## **Ejemplo de un caso de uso: Asistente de investigación científica**\n",
        "Imaginemos que necesitamos construir un asistente de investigación académica que ayude a científicos a encontrar artículos de investigación relevantes sobre un tema particular. Este caso describe conceptualmente la construcción de un asistente académico capaz de transformar preguntas en lenguaje natural en hallazgos verificables. La solución prioriza trazabilidad y control, cada decisión del sistema queda guardada en un estado persistente, y los pasos críticos se someten a validación humana antes de la entrega final."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM3eYdtUkECo"
      },
      "source": [
        "## **1. Instalación de dependencias**\n",
        "\n",
        "Primero, instalamos las librerías necesarias para que el grafo de LangGraph y sus utilidades funcionen correctamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "in8XAuhPkECo"
      },
      "outputs": [],
      "source": [
        "!pip install langgraph>=1.0.0 Pillow langsmith"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sg1zutNjkECp"
      },
      "source": [
        "## **2. Definición de clases y funciones de utilidad**\n",
        "\n",
        "A continuación, definimos todo el código de los módulos auxiliares (`state.py`, `utils.py`, `graph_utils.py`) en celdas separadas para mantener el orden.\n",
        "\n",
        "### **Definición de la Memoria o el estado del agente**\n",
        "Antes de que cualquier acción ocurra en el grafo en LangGraph, se necesita definir la memoria o el estado que compartirá todo el agente. Se utiliza `TypedDict` de Python para crear una estructura llamada `ResearchState`, que actúa como el contenedor central de datos.\n",
        "\n",
        "`ResearchState`: comienza conteniendo solo el tema de investigación. A medida que pasa por los diferentes pasos, cada nodo lee esta estructura, realiza su tarea (como generar queries o evaluar si los resultados son suficientes) y añade o actualiza la información antes de pasarla al siguiente nodo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "tags": [],
        "id": "BFkWDt3akECp"
      },
      "outputs": [],
      "source": [
        "from typing import List, TypedDict\n",
        "\n",
        "class ResearchState(TypedDict):\n",
        "    \"\"\"\n",
        "    Representa el estado actual del proceso de investigación.\n",
        "    \"\"\"\n",
        "    topic: str\n",
        "    queries: List[str]\n",
        "    raw_results: List[str]\n",
        "    iteration_count: int\n",
        "    is_sufficient: bool\n",
        "    report_draft: str\n",
        "    human_feedback: str"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La función `simular_carga` está diseñada para simular un retraso o una operación de carga en la consola, mostrando una barra de progreso animada."
      ],
      "metadata": {
        "id": "TSZw7q6IZUO5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ahgJEBz2kECp"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import time\n",
        "\n",
        "def simular_carga(segundos: int = 3, mensaje: str = \"Procesando\"):\n",
        "    \"\"\"\n",
        "    Simula un retraso con una barra de carga animada en la consola.\n",
        "    \"\"\"\n",
        "    ancho_barra = 30\n",
        "    intervalo = segundos / ancho_barra\n",
        "\n",
        "    sys.stdout.write(f\"\\n{mensaje} [\")\n",
        "    sys.stdout.flush()\n",
        "\n",
        "    for _ in range(ancho_barra):\n",
        "        time.sleep(intervalo)\n",
        "        sys.stdout.write(\"=\")\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    sys.stdout.write(\"] Listo!\\n\")\n",
        "    sys.stdout.flush()\n",
        "    time.sleep(0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La función `save_graph_image` toma una instancia de `StateGraph`y un nombre de archivo como entrada. Su propósito es generar una representación visual de ese grafo y guardarla como un archivo de imagen PNG. Internamente, utiliza el método `draw_mermaid_png(`) del grafo para obtener los bytes de la imagen. Esto es útil para depurar, documentar o simplemente entender la estructura de un flujo de trabajo de LangGraph."
      ],
      "metadata": {
        "id": "1vJ2waUYZeWV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hwdAY0OBkECp"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import io\n",
        "from langgraph.graph import StateGraph\n",
        "\n",
        "def save_graph_image(graph: StateGraph, filename: str = \"research_assistant_mockup.png\"):\n",
        "    \"\"\"\n",
        "    Genera y guarda una imagen del grafo de LangGraph en formato PNG.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        image_bytes = graph.get_graph().draw_mermaid_png()\n",
        "        image = Image.open(io.BytesIO(image_bytes))\n",
        "        image.save(filename)\n",
        "        print(f\"\\nImagen del grafo guardada como '{filename}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"(No se pudo generar la imagen del grafo por falta de dependencias opcionales o error: {e})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk-PvR9rkECp"
      },
      "source": [
        "## 3. Lógica Principal del Grafo de Investigación\n",
        "\n",
        "Esta es la celda principal que contiene la lógica del `main.py` original. Aquí se definen los nodos, las aristas y la lógica condicional del grafo.\n",
        "\n",
        "### **Nodo generar consulta**\n",
        "El primer paso operativo del flujo en el grafo es el nodo `node_generate_queries`, que actúa como el punto de partida del agente. Su función es tomar el tema general de investigación almacenado en el estado y traducirlo en acciones concretas: una lista de consultas de búsqueda.\n",
        "\n",
        "En este bloque, simulamos el comportamiento de una IA compleja que '***piensa***' (representado por la barra de carga) para descomponer el tema principal en sub-búsquedas estratégicas, como buscar principios básicos, avances recientes o metodologías relacionadas. Al finalizar su tarea, este nodo actualiza nuestro estado compartido con estas nuevas consultas y reinicia los contadores de seguimiento, dejando todo listo para que el siguiente nodo ejecute la búsqueda."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "from typing import Annotated, List, Literal, Union\n",
        "from langgraph.graph import END, START, StateGraph\n",
        "\n",
        "# --- Nodos del Grafo (Mockups Funcionales) ---\n",
        "def node_generate_queries(state: ResearchState) -> ResearchState:\n",
        "    simular_carga(3, \"Iniciando motor de razonamiento\")\n",
        "    print(f\"\\n\\n===== [node_generate_queries] =====\\n\")\n",
        "    print(f\"   - Tema de Investigación: '{state['topic']}'\")\n",
        "    new_queries = [f\"principios {state['topic']}\", f\"avances recientes {state['topic']}\", f\"{state['topic']} metodología\"]\n",
        "    print(f\"   - Consultas Generadas: {new_queries}\")\n",
        "    return {\n",
        "        \"queries\": new_queries,\n",
        "        \"iteration_count\": 0,\n",
        "        \"human_feedback\": \"pending\"\n",
        "    }"
      ],
      "metadata": {
        "id": "T5Q5qweuJ9Wf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Nodos de búsqueda**\n",
        "Una vez que tenemos la lista de consultas de búsqueda, el agente entra en un ciclo crítico de búsqueda y evaluación, representado por los nodos `node_search_api` y` node_evaluate_results`. Primero, `node_search_api` toma las consultas del estado y simula una conexión a bases de datos académicas externas, devolviendo una lista preliminar de documentos."
      ],
      "metadata": {
        "id": "pY2OH95LKp8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def node_search_api(state: ResearchState) -> ResearchState:\n",
        "    simular_carga(3, \"Consultando bases de datos externas\")\n",
        "    print(f\"\\n\\n===== [node_search_api] =====\\n\")\n",
        "    print(f\"   - Ejecutando Consultas: {state['queries']}\")\n",
        "    if state[\"iteration_count\"] == 0:\n",
        "        results = [\"Paper A (muy antiguo)\", \"Paper B (poco relevante)\"]\n",
        "    else:\n",
        "        results = [\"Paper A\", \"Paper B\", \"Paper C (relevante, 2024)\", \"Paper D (survey seminal)\"]\n",
        "    print(f\"   - Resultados Encontrados: {len(results)} documentos.\")\n",
        "    return {\"raw_results\": results}"
      ],
      "metadata": {
        "id": "8amr1DjWatDV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Nodo de evaluación de resultados**\n",
        "Después, `node_evaluate_results` actúa como un filtro de calidad, analiza si la cantidad y relevancia de estos resultados cumplen con nuestros criterios mínimos definidos (en este caso, simulado por un umbral de tres documentos). Este nodo no solo determina si podemos avanzar a la fase de escritura, sino que también incrementa el contador de iteraciones, un mecanismo clave para evitar que nuestro asistente se quede atrapado en un bucle de búsqueda infinito si no logra encontrar suficiente información."
      ],
      "metadata": {
        "id": "J8flWLNiavHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def node_evaluate_results(state: ResearchState) -> ResearchState:\n",
        "    simular_carga(2, \"Analizando relevancia\")\n",
        "    print(f\"\\n\\n===== [node_evaluate_results] =====\\n\")\n",
        "    is_sufficient = len(state[\"raw_results\"]) >= 3\n",
        "    if not is_sufficient:\n",
        "        print(\"   - Evaluación: INSUFICIENTE. Se requiere refinamiento.\")\n",
        "    else:\n",
        "        print(\"   - Evaluación: SUFICIENTE. Procediendo a síntesis.\")\n",
        "    return {\n",
        "        \"is_sufficient\": is_sufficient,\n",
        "        \"iteration_count\": state[\"iteration_count\"] + 1\n",
        "    }"
      ],
      "metadata": {
        "id": "5Fz7ut5NK1FH"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Nodo de refinar busqueda**\n",
        "Si la evaluación inicial resulta insuficiente, el flujo se desvía hacia `node_refine_search`. Este nodo actúa como un estratega que toma las consultas originales y las modifica (por ejemplo, añadiendo términos como review para buscar artículos de revisión más amplios), preparándolas para una nueva ronda de búsqueda."
      ],
      "metadata": {
        "id": "kSbD3v1UK4XI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def node_refine_search(state: ResearchState) -> ResearchState:\n",
        "    simular_carga(2, \"Ajustando parámetros de búsqueda\")\n",
        "    print(f\"\\n\\n===== [node_refine_search] =====\\n\")\n",
        "    new_queries = [q + \" review\" for q in state[\"queries\"]]\n",
        "    print(f\"   - Nuevas Consultas Generadas: {len(new_queries)}\")\n",
        "    return {\"queries\": new_queries}"
      ],
      "metadata": {
        "id": "7YW1o9sWbAaK"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Nodo de sintetizar reporte**\n",
        "Una vez que los resultados son satisfactorios, el control pasa a `node_synthesize_report`. Este nodo toma toda la información recopilada y redacta un borrador preliminar, estructurando los hallazgos clave en un texto coherente.\n"
      ],
      "metadata": {
        "id": "8ESyRGpPbC67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def node_synthesize_report(state: ResearchState) -> ResearchState:\n",
        "    simular_carga(4, \"Redactando informe final\")\n",
        "    print(f\"\\n\\n===== [node_synthesize_report] =====\\n\")\n",
        "    draft = f\"INFORME SOBRE {state['topic'].upper()}\\nBasado en {len(state['raw_results'])} papers clave, el campo muestra...\"\n",
        "    print(\"   - Borrador de Informe Generado.\")\n",
        "    return {\"report_draft\": draft}"
      ],
      "metadata": {
        "id": "2a9nAfr8bIvX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Nodo de aprobación del humano**\n",
        "Finalmente, el proceso llega a `node_human_approval`, un que introduce al **human-in-the-loop**. Aquí, el sistema pausa (simbólicamente en este mockup) para presentar el borrador al usuario, esperando su veredicto final (aprobación o rechazo) antes de dar por terminada la tarea.\n"
      ],
      "metadata": {
        "id": "CLHL56mXbK2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def node_human_approval(state: ResearchState) -> ResearchState:\n",
        "    simular_carga(1, \"Preparando interfaz de revisión\")\n",
        "    print(f\"\\n\\n===== [node_human_approval] =====\\n\")\n",
        "    print(f\"   - Mostrando borrador al usuario para revisión:\\n\\n{state['report_draft']}\\n\")\n",
        "    simular_carga(2, \"Esperando input del usuario\")\n",
        "    print(\"\\n   >>> [Simulación] Usuario revisando... APROBADO.\\n\")\n",
        "    return {\"human_feedback\": \"approve\"}"
      ],
      "metadata": {
        "id": "EsbxGOTCLCK7"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Autonomía del agente**\n",
        "Para implementar autonomía al agente, se incorporan enrutadores o nodos de decisión lógica, que actúan como mecanismos de control que regulan el flujo del proceso en función de la información disponible en el estado. El componente `route_evaluation` constituye el primer punto de control, analiza la bandera de suficiencia y determina si el sistema puede avanzar hacia la fase de redacción o si, por el contrario, debe retornar a etapas previas para refinar los resultados."
      ],
      "metadata": {
        "id": "rvpIGiUyLQCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Lógica Condicional (Routers) ---\n",
        "def route_evaluation(state: ResearchState) -> Literal[\"synthesize_report\", \"refine_search\"]:\n",
        "    if state[\"is_sufficient\"]:\n",
        "        return \"synthesize_report\"\n",
        "    return \"refine_search\""
      ],
      "metadata": {
        "id": "45KhWxfSbPsM"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Decisión final**\n",
        "De manera complementaria, el componente `route_human_feedback` gestiona la decisión final a partir de la intervención humana; cuando el revisor aprueba el borrador, el flujo se dirige al nodo `END`, concluyendo el proceso, y en caso contrario se ordena un reinicio del ciclo de investigación. Estas bifurcaciones condicionales convierten una secuencia previamente lineal en un sistema dinámico y adaptable, capaz de ajustar su trayectoria en función del desempeño observado."
      ],
      "metadata": {
        "id": "cfPbYNVybRpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def route_human_feedback(state: ResearchState) -> Literal[END, \"generate_queries\"]:\n",
        "    if state[\"human_feedback\"] == \"approve\":\n",
        "        print(\"\\n\\n===== PROCESO FINALIZADO CON ÉXITO =====\\n\")\n",
        "        print(\"   - Informe entregado satisfactoriamente.\\n\")\n",
        "        return END\n",
        "    print(\"\\n\\n===== FEEDBACK NEGATIVO =====\\n\")\n",
        "    print(\"   - Reiniciando proceso de investigación.\\n\")\n",
        "    return \"generate_queries\""
      ],
      "metadata": {
        "id": "hzkwtLbsLgCJ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Construcción del grafo**\n",
        "En la fase de construcción del grafo se integran los componentes operativos dentro de una arquitectura ejecutable. Se inicializa el `StateGraph` que es el constructor utilizado para definir el flujo de trabajo del agente y al pasar ResearchState como argumento, se define que todos los nodos en este grafo deben recibir y devolver datos que se ajusten a esa estructura específica (`TypedDict`).\n",
        "\n",
        "A continuación, se traza la topología del flujo de datos, se emplean aristas (`add_edge`) para establecer secuencias determinísticas y aristas condicionales (`add_conditional_edges`) en los puntos de control donde los enrutadores deben seleccionar dinámicamente el siguiente estado (ejemplo, evaluar calidad o esperar aprobación).\n",
        "\n",
        "La invocación final a `compile()` construye una máquina de estados lista para la ejecución de tareas."
      ],
      "metadata": {
        "id": "ihJmHlqaLjL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Construcción del Grafo ---\n",
        "builder = StateGraph(ResearchState)\n",
        "builder.add_node(\"generate_queries\", node_generate_queries)\n",
        "builder.add_node(\"search_api\", node_search_api)\n",
        "builder.add_node(\"evaluate_results\", node_evaluate_results)\n",
        "builder.add_node(\"refine_search\", node_refine_search)\n",
        "builder.add_node(\"synthesize_report\", node_synthesize_report)\n",
        "builder.add_node(\"human_approval\", node_human_approval)\n",
        "builder.add_edge(START, \"generate_queries\")\n",
        "builder.add_edge(\"generate_queries\", \"search_api\")\n",
        "builder.add_edge(\"search_api\", \"evaluate_results\")\n",
        "builder.add_conditional_edges(\"evaluate_results\", route_evaluation)\n",
        "builder.add_edge(\"refine_search\", \"search_api\")\n",
        "builder.add_edge(\"synthesize_report\", \"human_approval\")\n",
        "builder.add_conditional_edges(\"human_approval\", route_human_feedback)\n",
        "graph = builder.compile()"
      ],
      "metadata": {
        "id": "vhtk4O-qLo80"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ejecución del grafo**\n",
        "Finalmente se instancia el ResearchState inicial, especificando el tema de investigación a explorar (ejemplo, el impacto de la IA en la educación) y manteniendo vacíos los campos restantes, a modo de estado inicial.\n",
        "\n",
        "A continuación, una llamada a graph.invoke(initial_state) inicia la ejecución. La función toma el estado inicial e inyecta la información en el nodo de arranque (START), ejecutando el grafo, en el que cada nodo cumple con su función y transfiere el control al siguiente hasta finalizar el proceso."
      ],
      "metadata": {
        "id": "KZxeninALr3Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj2lFYgUkECq",
        "outputId": "ad984aab-7efa-4a1c-c277-4e250949faa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Imagen del grafo guardada como 'research_assistant_mockup.png'\n",
            "\n",
            "\n",
            "************************************************\n",
            "***** Iniciando Asistente de Investigación *****\n",
            "************************************************\n",
            "\n",
            "\n",
            "Iniciando motor de razonamiento [==============================] Listo!\n",
            "\n",
            "\n",
            "===== [node_generate_queries] =====\n",
            "\n",
            "   - Tema de Investigación: 'Impacto de la IA generativa en la educación superior'\n",
            "   - Consultas Generadas: ['principios Impacto de la IA generativa en la educación superior', 'avances recientes Impacto de la IA generativa en la educación superior', 'Impacto de la IA generativa en la educación superior metodología']\n",
            "\n",
            "Consultando bases de datos externas [==============================] Listo!\n",
            "\n",
            "\n",
            "===== [node_search_api] =====\n",
            "\n",
            "   - Ejecutando Consultas: ['principios Impacto de la IA generativa en la educación superior', 'avances recientes Impacto de la IA generativa en la educación superior', 'Impacto de la IA generativa en la educación superior metodología']\n",
            "   - Resultados Encontrados: 2 documentos.\n",
            "\n",
            "Analizando relevancia [==============================] Listo!\n",
            "\n",
            "\n",
            "===== [node_evaluate_results] =====\n",
            "\n",
            "   - Evaluación: INSUFICIENTE. Se requiere refinamiento.\n",
            "\n",
            "Ajustando parámetros de búsqueda [==============================] Listo!\n",
            "\n",
            "\n",
            "===== [node_refine_search] =====\n",
            "\n",
            "   - Nuevas Consultas Generadas: 3\n",
            "\n",
            "Consultando bases de datos externas [==============================] Listo!\n",
            "\n",
            "\n",
            "===== [node_search_api] =====\n",
            "\n",
            "   - Ejecutando Consultas: ['principios Impacto de la IA generativa en la educación superior review', 'avances recientes Impacto de la IA generativa en la educación superior review', 'Impacto de la IA generativa en la educación superior metodología review']\n",
            "   - Resultados Encontrados: 4 documentos.\n",
            "\n",
            "Analizando relevancia [==============================] Listo!\n",
            "\n",
            "\n",
            "===== [node_evaluate_results] =====\n",
            "\n",
            "   - Evaluación: SUFICIENTE. Procediendo a síntesis.\n",
            "\n",
            "Redactando informe final [==============================] Listo!\n",
            "\n",
            "\n",
            "===== [node_synthesize_report] =====\n",
            "\n",
            "   - Borrador de Informe Generado.\n",
            "\n",
            "Preparando interfaz de revisión [==============================] Listo!\n",
            "\n",
            "\n",
            "===== [node_human_approval] =====\n",
            "\n",
            "   - Mostrando borrador al usuario para revisión:\n",
            "\n",
            "INFORME SOBRE IMPACTO DE LA IA GENERATIVA EN LA EDUCACIÓN SUPERIOR\n",
            "Basado en 4 papers clave, el campo muestra...\n",
            "\n",
            "\n",
            "Esperando input del usuario [==============================] Listo!\n",
            "\n",
            "   >>> [Simulación] Usuario revisando... APROBADO.\n",
            "\n",
            "\n",
            "\n",
            "===== PROCESO FINALIZADO CON ÉXITO =====\n",
            "\n",
            "   - Informe entregado satisfactoriamente.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# --- Ejecución y Visualización ---\n",
        "save_graph_image(graph, \"research_assistant_mockup.png\")\n",
        "initial_state = ResearchState(\n",
        "    topic = \"Impacto de la IA generativa en la educación superior\",\n",
        "    queries = [], raw_results = [], iteration_count = 0,\n",
        "    is_sufficient = False, report_draft=\"\", human_feedback = \"pending\"\n",
        ")\n",
        "print(\"\\n\\n************************************************\")\n",
        "print(\"***** Iniciando Asistente de Investigación *****\")\n",
        "print(\"************************************************\\n\")\n",
        "final_state = graph.invoke(\n",
        "    initial_state,\n",
        "    config={\"tags\": [\"research_workflow\", \"generative_ai_education\"]}\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}